{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import *\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_utils import Config, BertPreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(\n",
    "    model_type=\"bert-base-uncased\",\n",
    "    max_seq_len=128,\n",
    "    subspace_size=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = BertPreprocessor(config.model_type, config.max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): BertLayerNorm()\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=30522, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_pretrained_bert import BertConfig, BertForMaskedLM\n",
    "model = BertForMaskedLM.from_pretrained(config.model_type)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class ContextWord:\n",
    "    sent: str\n",
    "    word: str\n",
    "    def __post_init__(self):\n",
    "        assert self.word in self.sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(x, y):\n",
    "    return np.dot(x, y) / (np.linalg.norm(x) * np.linalg.norm(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_vector(cword: ContextWord, use_last_mask=False):\n",
    "    sentence, word = cword.sent, cword.word\n",
    "    idx = processor.get_index(sentence, word, last=use_last_mask)\n",
    "    outputs = None\n",
    "    with torch.no_grad():\n",
    "        sequence_output, _ = model.bert(processor.to_bert_model_input(sentence),\n",
    "                                        output_all_encoded_layers=False)\n",
    "        sequence_output.squeeze_(0)\n",
    "        if outputs is None: outputs = torch.zeros_like(sequence_output)\n",
    "        outputs = sequence_output + outputs\n",
    "    return outputs.detach().cpu().numpy()[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_sim_matrix(vecs):\n",
    "    sim_matrix = np.zeros((len(vecs), len(vecs)))\n",
    "    for i, v in enumerate(vecs):\n",
    "        for j, w in enumerate(vecs):\n",
    "            sim_matrix[i, j] = cosine_similarity(v, w)\n",
    "    return sim_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_sim_matrix_df(sentences: List[str],\n",
    "                           words: List[str]):\n",
    "    sim = construct_sim_matrix([get_word_vector(ContextWord(sent, word)) for sent, word in zip(sentences, words)])\n",
    "    return pd.DataFrame(data=sim, index=words, columns=words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_diff_similarity(cwords1, cwords2):\n",
    "    cword11, cword12 = cwords1\n",
    "    cword21, cword22 = cwords2\n",
    "    return cosine_similarity(get_word_vector(cword11) - get_word_vector(cword12),\n",
    "                             get_word_vector(cword21) - get_word_vector(cword22))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_softmax = model.cls.predictions.decoder.weight.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_bias = model.cls.predictions.bias.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_logits(wv: np.ndarray) -> np.ndarray:\n",
    "    return model.cls(torch.FloatTensor(wv).unsqueeze(0)).detach().cpu().numpy()[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>programmer</th>\n",
       "      <th>man</th>\n",
       "      <th>woman</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>programmer</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.390309</td>\n",
       "      <td>0.413819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>man</th>\n",
       "      <td>0.390309</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.824558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>woman</th>\n",
       "      <td>0.413819</td>\n",
       "      <td>0.824558</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            programmer       man     woman\n",
       "programmer    1.000000  0.390309  0.413819\n",
       "man           0.390309  1.000000  0.824558\n",
       "woman         0.413819  0.824558  1.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "construct_sim_matrix_df([\"That person is a programmer.\", \n",
    "                         \"I am a man.\", \n",
    "                         \"I am a woman.\"],\n",
    "                       [\"programmer\", \"man\", \"woman\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.150812"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_diff_similarity(\n",
    "    (ContextWord(\"I am a man.\", \"man\"), ContextWord(\"I am a woman.\", \"woman\")),\n",
    "    (ContextWord(\"The programmer went to the office.\", \"programmer\"),\n",
    "     ContextWord(\"The nurse went to the office.\", \"nurse\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23052038"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_diff_similarity(\n",
    "    (ContextWord(\"I am a man.\", \"man\"), ContextWord(\"I am a woman.\", \"woman\")),\n",
    "    (ContextWord(\"The doctor went to the office.\", \"doctor\"),\n",
    "     ContextWord(\"The nurse went to the office.\", \"nurse\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31024477"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_diff_similarity(\n",
    "    (ContextWord(\"he likes sports.\", \"he\"), ContextWord(\"she likes sports.\", \"she\")),\n",
    "    (ContextWord(\"The doctor went to the office.\", \"doctor\"),\n",
    "     ContextWord(\"The nurse went to the office.\", \"nurse\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find gendered direction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original gender terms:\n",
    "- she - he \n",
    "- her - his \n",
    "- woman - man\n",
    "- Mary - John\n",
    "- herself - himself\n",
    "- daughter - son\n",
    "- mother - father\n",
    "- gal - guy\n",
    "- girl - boy\n",
    "- female - male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_vecs, female_vecs = [], []\n",
    "def add_word_vecs(s: str, male_w: str, female_w: str):\n",
    "    male_vecs.append(get_word_vector(ContextWord(s.replace(\"XXX\", male_w), male_w)))\n",
    "    female_vecs.append(get_word_vector(ContextWord(s.replace(\"XXX\", female_w), female_w)))\n",
    "\n",
    "for prof in [\"musician\", \"magician\", \"nurse\", \"doctor\", \"teacher\"]:\n",
    "    add_word_vecs(\"XXX is a YYY\".replace(\"YYY\", prof), \"he\", \"she\")\n",
    "    add_word_vecs(\"XXX works as a YYY\".replace(\"YYY\", prof), \"he\", \"she\")\n",
    "\n",
    "for action in [\"talk to\", \"hit\", \"ignore\", \"please\", \"remove\"]:\n",
    "    add_word_vecs(\"please YYY XXX\".replace(\"YYY\", action), \"him\", \"her\")\n",
    "    add_word_vecs(\"don't YYY XXX\".replace(\"YYY\", action), \"him\", \"her\")\n",
    "\n",
    "for thing in [\"food\", \"music\", \"work\", \"running\", \"cooking\"]:\n",
    "    add_word_vecs(\"XXX dislikes YYY\".replace(\"YYY\", thing), \"man\", \"woman\")\n",
    "    add_word_vecs(\"XXX is thinking about YYY\".replace(\"YYY\", thing), \"man\", \"woman\")\n",
    "    \n",
    "for action in [\"running\", \"thinking\", \"working\", \"watching\", \"reading\"]:\n",
    "    add_word_vecs(\"The XXX is YYY\".replace(\"YYY\", action), \"boy\", \"girl\")\n",
    "    add_word_vecs(\"That XXX likes YYY\".replace(\"YYY\", action), \"boy\", \"girl\")\n",
    "    \n",
    "for adj in [\"fat\", \"cute\", \"attractive\", \"smart\", \"strong\"]:\n",
    "    add_word_vecs(\"My XXX is YYY\".replace(\"YYY\", adj), \"boy\", \"girl\")\n",
    "    add_word_vecs(\"Her XXX is not YYY\".replace(\"YYY\", adj), \"boy\", \"girl\")\n",
    "    \n",
    "for thing in [\"cat\", \"dog\", \"person\", \"word\", \"action\"]:\n",
    "    add_word_vecs(\"XXX is YYY\".replace(\"YYY\", adj), \"male\", \"female\")\n",
    "    add_word_vecs(\"XXX is clearly YYY\".replace(\"YYY\", adj), \"male\", \"female\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_vecs = np.r_[male_vecs]\n",
    "female_vecs = np.r_[female_vecs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "def find_subspace(D: np.ndarray) -> PCA:\n",
    "    assert len(D.shape) == 2\n",
    "    pca = PCA(n_components=config.subspace_size)\n",
    "    return pca.fit(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = find_subspace(male_vecs - female_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1f1842cbb70>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x=np.arange(pca.n_components), y=pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what it says in the paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We denote the projection of a vector $ v $ onto $ B $ by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ v_B = \\sum_{j=1}^{k} (v \\cdot b_j) b_j $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each word $ w \\in N $, let $ \\vec{w} $ be re-embedded to\n",
    "$$ \\vec{w} := \\vec{w} - \\vec{w_{B}} / || \\vec{w} - \\vec{w_{B}} || $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\mu := \\sum_{w \\in E}w / |E| $$\n",
    "$$ \\nu := \\mu - \\mu_B $$\n",
    "For each $ w \\in E $, \n",
    "$$ \\vec{w} := \\nu + \\sqrt{1 - ||\\nu||^2}\\frac{\\vec{w_B} - \\mu_B}{||\\vec{w_B} - \\mu_B||} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_subspace(X: np.ndarray, subspace: np.ndarray, norm=True) -> np.ndarray:\n",
    "    Xb = ((X @ subspace.T) @ subspace) # projection onto biased subspace\n",
    "    X = (X - Xb) / (np.linalg.norm(X - Xb))\n",
    "    if norm:\n",
    "        mu = X.mean(0)\n",
    "        mub = Xb.mean(0)\n",
    "        nu = mu - mub\n",
    "        return nu + np.sqrt(1 - nu**2) * (Xb - mub) / np.linalg.norm(Xb - mub)\n",
    "    else:\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06290083, -0.09486502, -0.02813738, ..., -0.0434244 ,\n",
       "        -0.10185691,  0.06568632],\n",
       "       [-0.06342983, -0.09343779, -0.03166611, ..., -0.04076833,\n",
       "        -0.10113911,  0.06436379],\n",
       "       [-0.06442951, -0.09383111, -0.03182624, ..., -0.04132361,\n",
       "        -0.10287195,  0.06333559],\n",
       "       ...,\n",
       "       [-0.06907063, -0.10305101, -0.02295182, ..., -0.05188037,\n",
       "        -0.11271325,  0.06733435],\n",
       "       [-0.06983958, -0.10438704, -0.02219143, ..., -0.05312202,\n",
       "        -0.11442154,  0.06829499],\n",
       "       [-0.06907063, -0.10305101, -0.02295182, ..., -0.05188037,\n",
       "        -0.11271325,  0.06733435]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_subspace(male_vecs, pca.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Newly checking for differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pp(X: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Postprocess\"\"\"\n",
    "    return remove_subspace(np.expand_dims(X, 0), pca.components_, norm=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_new_diff_similarity(cwords1, cwords2):\n",
    "    cword11, cword12 = cwords1\n",
    "    cword21, cword22 = cwords2\n",
    "    return cosine_similarity(pp(get_word_vector(cword11)) - pp(get_word_vector(cword12)),\n",
    "                             pp(get_word_vector(cword21)) - pp(get_word_vector(cword22)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarities are being reduced, so there is a shared gender subspace to a certain extent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.150812, 0.12542932)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(compute_diff_similarity(\n",
    "    (ContextWord(\"I am a man.\", \"man\"), ContextWord(\"I am a woman.\", \"woman\")),\n",
    "    (ContextWord(\"The programmer went to the office.\", \"programmer\"),\n",
    "     ContextWord(\"The nurse went to the office.\", \"nurse\"))\n",
    "),\n",
    "compute_new_diff_similarity(\n",
    "    (ContextWord(\"I am a man.\", \"man\"), ContextWord(\"I am a woman.\", \"woman\")),\n",
    "    (ContextWord(\"The programmer went to the office.\", \"programmer\"),\n",
    "     ContextWord(\"The nurse went to the office.\", \"nurse\"))\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.23052038, 0.14701235)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(compute_diff_similarity(\n",
    "    (ContextWord(\"I am a man.\", \"man\"), ContextWord(\"I am a woman.\", \"woman\")),\n",
    "    (ContextWord(\"The doctor went to the office.\", \"doctor\"),\n",
    "     ContextWord(\"The nurse went to the office.\", \"nurse\"))\n",
    "),\n",
    "compute_new_diff_similarity(\n",
    "    (ContextWord(\"I am a man.\", \"man\"), ContextWord(\"I am a woman.\", \"woman\")),\n",
    "    (ContextWord(\"The doctor went to the office.\", \"doctor\"),\n",
    "     ContextWord(\"The nurse went to the office.\", \"nurse\"))\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.31024477, 0.23461927)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(compute_diff_similarity(\n",
    "    (ContextWord(\"he likes sports.\", \"he\"), ContextWord(\"she likes sports.\", \"she\")),\n",
    "    (ContextWord(\"The doctor went to the office.\", \"doctor\"),\n",
    "     ContextWord(\"The nurse went to the office.\", \"nurse\"))\n",
    "),\n",
    "compute_new_diff_similarity(\n",
    "    (ContextWord(\"he likes sports.\", \"he\"), ContextWord(\"she likes sports.\", \"she\")),\n",
    "    (ContextWord(\"The doctor went to the office.\", \"doctor\"),\n",
    "     ContextWord(\"The nurse went to the office.\", \"nurse\"))\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking for change in bias score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if the bias score decreases with this transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_score(sentence: str, gender_words: Iterable[str], \n",
    "               word: str, gender_comes_first=True, \n",
    "               correct_bias=True,\n",
    "               postprocess=False) -> float:    \n",
    "    mw, fw = gender_words\n",
    "    mwi, fwi = processor.token_to_index(mw), processor.token_to_index(fw)\n",
    "    wv = get_word_vector(\n",
    "        ContextWord(sentence.replace(\"XXX\", word).replace(\"GGG\", \"[MASK]\"), \"[MASK]\"),\n",
    "        use_last_mask=not gender_comes_first,        \n",
    "    )\n",
    "    if postprocess: wv = pp(wv)\n",
    "    logits = to_logits(wv)\n",
    "    subject_fill_bias = logits[mwi] - logits[fwi]\n",
    "    if correct_bias:\n",
    "        wv = get_word_vector(\n",
    "            ContextWord(sentence.replace(\"XXX\", \"[MASK]\").replace(\"GGG\", \"[MASK]\"), \"[MASK]\"),\n",
    "            use_last_mask=gender_comes_first,\n",
    "        )\n",
    "        if postprocess: wv = pp(wv)\n",
    "        prior_logits = to_logits(wv)\n",
    "        prior_bias = prior_logits[mwi] - prior_logits[fwi]\n",
    "        subject_fill_bias = subject_fill_bias - prior_bias\n",
    "    return subject_fill_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bias is reduced here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6938139"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_score(\"GGG is a XXX.\", [\"he\", \"she\"], \"doctor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.13400555"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_score(\"GGG is a XXX.\", [\"he\", \"she\"], \"doctor\", postprocess=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bias is neutralized here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.4922547"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_score(\"GGG is a XXX.\", [\"he\", \"she\"], \"nurse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.8503208"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_score(\"GGG is a XXX.\", [\"he\", \"she\"], \"nurse\", postprocess=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing for adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.395012"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_score(\"GGG is very XXX.\", [\"he\", \"she\"], \"beautiful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9436301"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_score(\"GGG is very XXX.\", [\"he\", \"she\"], \"beautiful\", postprocess=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5123712"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_score(\"GGG is very XXX.\", [\"he\", \"she\"], \"dangerous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.26822817"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_score(\"GGG is very XXX.\", [\"he\", \"she\"], \"dangerous\", postprocess=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2886461"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_score(\"GGG is very XXX.\", [\"he\", \"she\"], \"cute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.4273516"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_score(\"GGG is very XXX.\", [\"he\", \"she\"], \"cute\", postprocess=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unintended Side Effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are there any unintended side effects of this transformation? Let's test and see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.009464249"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_diff_similarity(\n",
    "    (ContextWord(\"I am a man.\", \"man\"), ContextWord(\"I am a woman.\", \"woman\")),\n",
    "    (ContextWord(\"The programmer went to the office.\", \"programmer\"),\n",
    "     ContextWord(\"The doctor went to the office.\", \"doctor\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    " def construct_sim_matrix_df(cws: List[ContextWord]):\n",
    "    return pd.DataFrame(data=sim, index=words, columns=words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>programmer</th>\n",
       "      <th>doctor</th>\n",
       "      <th>nurse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>programmer</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.683078</td>\n",
       "      <td>0.634901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doctor</th>\n",
       "      <td>0.683078</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.835144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nurse</th>\n",
       "      <td>0.634901</td>\n",
       "      <td>0.835144</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            programmer    doctor     nurse\n",
       "programmer    1.000000  0.683078  0.634901\n",
       "doctor        0.683078  1.000000  0.835144\n",
       "nurse         0.634901  0.835144  1.000000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cws = [\n",
    "    ContextWord(\"The programmer went to the office.\", \"programmer\"),\n",
    "    ContextWord(\"The doctor went to the office.\", \"doctor\"),\n",
    "    ContextWord(\"The nurse went to the office.\", \"nurse\"),\n",
    "]\n",
    "sim = construct_sim_matrix([get_word_vector(cw) for cw in cws])\n",
    "pd.DataFrame(data=sim, index=[cw.word for cw in cws], columns=[cw.word for cw in cws])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, the similarities here seem to be roughly preserved; perhaps because we are neutralizing w.r.t to the gender dimension in the subject space, but not the object space?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>programmer</th>\n",
       "      <th>doctor</th>\n",
       "      <th>nurse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>programmer</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.678573</td>\n",
       "      <td>0.630049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doctor</th>\n",
       "      <td>0.678573</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.832840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nurse</th>\n",
       "      <td>0.630049</td>\n",
       "      <td>0.832840</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            programmer    doctor     nurse\n",
       "programmer    1.000000  0.678573  0.630049\n",
       "doctor        0.678573  1.000000  0.832840\n",
       "nurse         0.630049  0.832840  1.000000"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim = construct_sim_matrix([pp(get_word_vector(cw)) for cw in cws])\n",
    "pd.DataFrame(data=sim, index=[cw.word for cw in cws], columns=[cw.word for cw in cws])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beautiful</th>\n",
       "      <th>dangerous</th>\n",
       "      <th>normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beautiful</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600859</td>\n",
       "      <td>0.583575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dangerous</th>\n",
       "      <td>0.600859</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.536445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normal</th>\n",
       "      <td>0.583575</td>\n",
       "      <td>0.536445</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           beautiful  dangerous    normal\n",
       "beautiful   1.000000   0.600859  0.583575\n",
       "dangerous   0.600859   1.000000  0.536445\n",
       "normal      0.583575   0.536445  1.000000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cws = [\n",
    "    ContextWord(\"Your colleague is very beautiful.\", \"beautiful\"),\n",
    "    ContextWord(\"Your colleague is very dangerous.\", \"dangerous\"),\n",
    "    ContextWord(\"Your colleague is very normal.\", \"normal\"),\n",
    "]\n",
    "sim = construct_sim_matrix([get_word_vector(cw) for cw in cws])\n",
    "pd.DataFrame(data=sim, index=[cw.word for cw in cws], columns=[cw.word for cw in cws])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, not much reduction in similarities here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beautiful</th>\n",
       "      <th>dangerous</th>\n",
       "      <th>normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beautiful</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.601322</td>\n",
       "      <td>0.581689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dangerous</th>\n",
       "      <td>0.601322</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.525321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normal</th>\n",
       "      <td>0.581689</td>\n",
       "      <td>0.525321</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           beautiful  dangerous    normal\n",
       "beautiful   1.000000   0.601322  0.581689\n",
       "dangerous   0.601322   1.000000  0.525321\n",
       "normal      0.581689   0.525321  1.000000"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim = construct_sim_matrix([pp(get_word_vector(cw)) for cw in cws])\n",
    "pd.DataFrame(data=sim, index=[cw.word for cw in cws], columns=[cw.word for cw in cws])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-linearity of BERT embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT embeddings no longer express the same linear semantics as word2vec/GloVe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5714916"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_diff_similarity(\n",
    "    (ContextWord(\"I am a man.\", \"man\"), ContextWord(\"I am a woman.\", \"woman\")),\n",
    "    (ContextWord(\"I am a king.\", \"king\"),\n",
    "     ContextWord(\"I am a queen.\", \"queen\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45550752"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_diff_similarity(\n",
    "    (ContextWord(\"he is my friend.\", \"he\"), ContextWord(\"she is my friend.\", \"she\")),\n",
    "    (ContextWord(\"they are the king.\", \"king\"),\n",
    "     ContextWord(\"they are the queen.\", \"queen\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference in direction does not stay constant as the subject/object status of the word changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35181317"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_diff_similarity(\n",
    "    (ContextWord(\"I am a man.\", \"man\"), ContextWord(\"I am a woman.\", \"woman\")),\n",
    "    (ContextWord(\"The king walked across the road.\", \"king\"),\n",
    "     ContextWord(\"The queen walked across the road.\", \"queen\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24944244"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_diff_similarity(\n",
    "    (ContextWord(\"I am a man.\", \"man\"), ContextWord(\"I am a woman.\", \"woman\")),\n",
    "    (ContextWord(\"king does not do such things.\", \"king\"),\n",
    "     ContextWord(\"queen does not do such things\", \"queen\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40263593"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_diff_similarity(\n",
    "    (ContextWord(\"I am a man.\", \"man\"), ContextWord(\"I am a woman.\", \"woman\")),\n",
    "    (ContextWord(\"I captured the opponent's king.\", \"king\"),\n",
    "     ContextWord(\"I captured the opponent's queen.\", \"queen\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21260609"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_diff_similarity(\n",
    "    (ContextWord(\"I am a man.\", \"man\"), ContextWord(\"I am a woman.\", \"woman\")),\n",
    "    (ContextWord(\"king, please forgive me!\", \"king\"),\n",
    "     ContextWord(\"queen, please forgive me!\", \"queen\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44601053"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_diff_similarity(\n",
    "    (ContextWord(\"his attitude is irritating.\", \"his\"), \n",
    "     ContextWord(\"her attitude is irritating.\", \"her\")),\n",
    "    (ContextWord(\"they are the king.\", \"king\"),\n",
    "     ContextWord(\"they are the queen.\", \"queen\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
