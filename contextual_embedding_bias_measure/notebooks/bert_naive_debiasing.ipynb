{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply debias BERT by optimizing the log odds ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import *\n",
    "import matplotlib.pyplot as plt\n",
    "from overrides import overrides\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "lr = 1e-5\n",
    "weight_reg = 1e-4\n",
    "train_file = \"gender_occ_pos_w_probs_train.txt\"\n",
    "val_file = \"gender_occ_pos_w_probs_val.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_utils import Config, BertPreprocessor\n",
    "config = Config(\n",
    "    model_type=\"bert-base-uncased\",\n",
    "    max_seq_len=24,\n",
    "    batch_size=32,\n",
    "    bias_weight=1., # technically unnecessary, but for easier debugging\n",
    "    consistency_weight=1.,\n",
    "    lr=lr,\n",
    "    weight_reg=weight_reg,\n",
    "    disable_dropout=True,\n",
    "    init_probs_precomputed=True,\n",
    "    testing=True,\n",
    "    remove_prior_bias=True,\n",
    "    epochs=3,\n",
    "    train_file=train_file,\n",
    "    val_file=val_file,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = TypeVar(\"T\")\n",
    "TensorDict = Dict[str, Union[torch.Tensor, Dict[str, torch.Tensor]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = BertPreprocessor(config.model_type, config.max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path(\"../data\")\n",
    "MODEL_SAVE_DIR = Path(\"../weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the model in here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_pretrained_bert import BertConfig, BertForMaskedLM\n",
    "masked_lm = BertForMaskedLM.from_pretrained(config.model_type)\n",
    "masked_lm.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout might be causing the model to be more uncertain, attributing lower probs to the correct sentence: disabling might help with logit explosion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.disable_dropout:\n",
    "    def disable_dropout(mod):\n",
    "        if hasattr(mod, \"named_children\"):\n",
    "            for nm, child in mod.named_children():\n",
    "                if \"dropout\" in nm: child.p = 0. # forcibly set to 0\n",
    "                disable_dropout(child)\n",
    "    disable_dropout(masked_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_lm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freeze positional embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_lm.bert.embeddings.position_embeddings.requires_grad = False\n",
    "masked_lm.bert.embeddings.token_type_embeddings.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freeze layer norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in masked_lm.named_parameters():\n",
    "    if \"LayerNorm\" in k: v.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.token_indexers import PretrainedBertIndexer\n",
    "\n",
    "def flatten(x: List[List[T]]) -> List[T]:\n",
    "        return [item for sublist in x for item in sublist]\n",
    "\n",
    "token_indexer = PretrainedBertIndexer(\n",
    "    pretrained_model=config.model_type,\n",
    "    max_pieces=config.max_seq_len,\n",
    "    do_lowercase=True,\n",
    " )\n",
    "\n",
    "def tokenizer(s: str):\n",
    "    maxlen = config.max_seq_len - 2\n",
    "    toks = token_indexer.wordpiece_tokenizer(s)[:maxlen]\n",
    "    return toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_np(t): return t.detach().cpu().numpy()\n",
    "\n",
    "def to_words(arr):\n",
    "    if len(arr.shape) > 1:\n",
    "        return [to_words(a) for a in arr]\n",
    "    else:\n",
    "        arr = to_np(arr)\n",
    "        return \" \".join([itot(i) for i in arr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_vocab = {v: k for k, v in token_indexer.vocab.items()}\n",
    "\n",
    "def ttoi(t: str): return token_indexer.vocab[t]\n",
    "def itot(i: int): return rev_vocab[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.vocabulary import Vocabulary\n",
    "global_vocab = Vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from allennlp.data import DatasetReader, Instance, Token\n",
    "from allennlp.data.fields import (TextField, SequenceLabelField, LabelField, \n",
    "                                  MetadataField, ArrayField)\n",
    "\n",
    "class BertTextField(TextField):\n",
    "    @overrides\n",
    "    def get_padding_lengths(self): # consistent padding lengths\n",
    "        pad_lengths = super().get_padding_lengths()\n",
    "        for k in pad_lengths.keys():\n",
    "            pad_lengths[k] = config.max_seq_len\n",
    "        return pad_lengths\n",
    "\n",
    "class LongArrayField(ArrayField):\n",
    "    @overrides\n",
    "    def as_tensor(self, padding_lengths: Dict[str, int]) -> torch.Tensor:\n",
    "        tensor = torch.from_numpy(self.array)\n",
    "        return tensor\n",
    "    \n",
    "class FloatArrayField(ArrayField):\n",
    "    @overrides\n",
    "    def as_tensor(self, padding_lengths: Dict[str, int]) -> torch.FloatTensor:\n",
    "        tensor = torch.FloatTensor(self.array)\n",
    "        return tensor\n",
    "\n",
    "class DebiasingDatasetReader(DatasetReader):\n",
    "    def __init__(self, tokenizer, token_indexers, \n",
    "                 init_probs_precomputed: bool=False,\n",
    "                 remove_prior_bias: bool=False,\n",
    "                 ) -> None:\n",
    "        super().__init__(lazy=False)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.token_indexers = token_indexers\n",
    "        self.vocab = token_indexers[\"tokens\"].vocab\n",
    "        self._init_probs_precomputed = init_probs_precomputed\n",
    "        self._remove_prior_bias = remove_prior_bias\n",
    "\n",
    "    def _proc(self, x):\n",
    "        if x == \"[MASK]\" or x == \"[PAD]\": return x\n",
    "        else: return x.lower()\n",
    "        \n",
    "    @overrides\n",
    "    def text_to_instance(self, tokens: List[str], w1: str, w2: str, \n",
    "                         p1: Optional[float], p2: Optional[float],\n",
    "                         desired_bias: Optional[float],\n",
    "                        ) -> Instance:\n",
    "        fields = {}\n",
    "        input_toks = [Token(self._proc(x)) for x in tokens]\n",
    "        fields[\"input\"] = BertTextField(input_toks, self.token_indexers)        \n",
    "        # take [CLS] token into account\n",
    "        mask_position = tokens.index(\"[MASK]\") + 1\n",
    "        fields[\"mask_positions\"] = LongArrayField(\n",
    "            np.array(mask_position, dtype=np.int64),\n",
    "         )\n",
    "        fields[\"target_ids\"] = LongArrayField(np.array([\n",
    "            self.vocab[w1], self.vocab[w2],\n",
    "        ], dtype=np.int64))\n",
    "                \n",
    "        if self._init_probs_precomputed:\n",
    "            fields[\"initial_prob_sum\"] = FloatArrayField(np.array(p1 + p2, dtype=np.float32))\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                bert_input = (self.token_indexers[\"tokens\"]\n",
    "                              .tokens_to_indices(input_toks, global_vocab, \"tokens\"))\n",
    "                token_ids = torch.LongTensor(bert_input[\"tokens\"]).unsqueeze(0)\n",
    "                probs = masked_lm(token_ids)[0, mask_position, :].detach().numpy()\n",
    "                probs = (probs - probs.max())\n",
    "                probs = probs.exp() / probs.exp().sum()\n",
    "                fields[\"initial_prob_sum\"] = \\\n",
    "                    FloatArrayField(np.array(probs[self.vocab[w1]] + probs[self.vocab[w2]],\n",
    "                               dtype=np.float32))\n",
    "            \n",
    "        if self._remove_prior_bias:\n",
    "            fields[\"desired_bias\"] = \\\n",
    "                FloatArrayField(np.array(desired_bias, dtype=np.float32))\n",
    "        \n",
    "        return Instance(fields)\n",
    "    \n",
    "    @overrides\n",
    "    def _read(self, file_path: str) -> Iterator[Instance]:\n",
    "        p1, p2 = 0., 0.\n",
    "        with open(file_path, \"rt\") as f:\n",
    "            reader = csv.reader(f)\n",
    "            next(reader) # skip header\n",
    "            for row in reader:\n",
    "                if self._init_probs_precomputed: \n",
    "                    sentence, w1, w2, tgt, p1, p2, prior_bias, bias_score = row\n",
    "                else: sentence, w1, w2, tgt = row\n",
    "                yield self.text_to_instance(\n",
    "                    self.tokenizer(sentence), \n",
    "                    w1, w2, # words\n",
    "                    float(p1), float(p2), # initial probs\n",
    "                    float(prior_bias), # prior bias\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = DebiasingDatasetReader(tokenizer=tokenizer, \n",
    "                                token_indexers={\"tokens\": token_indexer},\n",
    "                                init_probs_precomputed=config.init_probs_precomputed,\n",
    "                                remove_prior_bias=config.remove_prior_bias)\n",
    "train_ds, val_ds = (reader.read(DATA_ROOT / fname) for fname in [config.train_file, config.val_file])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars(train_ds[0].fields[\"input\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.iterators import BasicIterator\n",
    "\n",
    "iterator = BasicIterator(\n",
    "        batch_size=config.batch_size, \n",
    "    )\n",
    "iterator.index_with(global_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(iterator(train_ds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(x, y, desired=0): return ((x - y - desired) ** 2).mean()\n",
    "def mae_loss(x, y, desired=0): return (x - y - desired).abs().mean()\n",
    "class HingeLoss(nn.Module):\n",
    "    def __init__(self, margin: float=0.1):\n",
    "        super().__init__()\n",
    "        self.margin = margin\n",
    "    def forward(self, x, y, desired=0.):\n",
    "        return torch.relu((x - y - desired).abs().mean() - self.margin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_likelihood(ll, # (batch, )\n",
    "               initial_prob_sum, # (batch, )\n",
    "     ):\n",
    "    \"\"\"log likelihood of either of the target ids being chosen\"\"\"\n",
    "    return -ll.mean()\n",
    "\n",
    "class LogitConsistency(nn.Module):\n",
    "    def __init__(self, distance: Callable):\n",
    "        super().__init__()\n",
    "        self._distance = distance\n",
    "    \n",
    "    def forward(self, ll, # (batch, )\n",
    "                initial_prob_sum, # (batch, )\n",
    "               ):\n",
    "        \"\"\"\n",
    "        Constrains prob sum put on two words to be roughly equal\n",
    "        TODO: Provide some probabilistic/statistical interpretation\n",
    "        \"\"\"\n",
    "        d = self._distance(ll, initial_prob_sum.log())\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.training.metrics import Metric\n",
    "class TotalProbDiff(Metric):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._total = 0\n",
    "        self._n_obs = 0\n",
    "        \n",
    "    def __call__(self, ll, initial_prob_sum):\n",
    "        self._total += (ll.exp() - initial_prob_sum).mean().item()\n",
    "        self._n_obs += 1\n",
    "        \n",
    "    def get_metric(self, reset: bool=False):\n",
    "        mtrc = self._total / self._n_obs\n",
    "        if reset: self.reset()\n",
    "        return mtrc\n",
    "    \n",
    "    def reset(self):\n",
    "        self._total = 0\n",
    "        self._n_obs = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiasLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Returns the deviation of the log odds ratio from its desired value.\n",
    "    Denoting the probs as p and q there are several options available:\n",
    "        - MSE(log p, log q)\n",
    "        - Max-margin loss\n",
    "    Most processing takes place here because there is a lot of shared heavy processing required\n",
    "    (e.g. computing partition function)\n",
    "    TODO: Add option to set the optimal log odds ratio\n",
    "    TODO: Ensure the logits do not change significantly\n",
    "    \"\"\"\n",
    "    def __init__(self, loss_func: Callable=mae_loss,\n",
    "                 consistency_loss_func: Callable=LogitConsistency(mae_loss),\n",
    "                 bias_weight: float=1.,\n",
    "                 consistency_weight: float=1.):\n",
    "        super().__init__()\n",
    "        self.loss_func = loss_func\n",
    "        self._consistency_loss = consistency_loss_func\n",
    "        self.consistency_weight = consistency_weight\n",
    "        self.bias_weight = bias_weight\n",
    "        self._total_prob_diff = TotalProbDiff()\n",
    "    \n",
    "    @staticmethod\n",
    "    def _log_likelihood(logits, # (batch, V)\n",
    "                        target_logits, # (batch, )\n",
    "                       ) -> torch.FloatTensor: # (batch, )\n",
    "        max_logits = logits.max(1, keepdim=True)[0] # (batch, )\n",
    "        log_exp_sum_logits = ((logits - max_logits).exp()\n",
    "                              .sum(1).log()) # (batch, )\n",
    "        # these logits should never be masked\n",
    "        log_exp_sum_correct_logits = ((target_logits - max_logits).exp()\n",
    "                                      .sum(1).log()) # (batch, )\n",
    "        return log_exp_sum_correct_logits - log_exp_sum_logits\n",
    "        \n",
    "    def forward(self, logits: torch.FloatTensor, # (batch, seq, V)\n",
    "                mask_positions: torch.LongTensor, # (batch, )\n",
    "                target_ids: torch.LongTensor, # (batch, 2)\n",
    "                initial_prob_sum: torch.FloatTensor, # (batch, )\n",
    "                desired_bias: torch.FloatTensor=None,\n",
    "               ) -> torch.FloatTensor:\n",
    "        \"\"\"\n",
    "        input_ids: Numericalized tokens\n",
    "        mask_position: Positions of mask tokens\n",
    "        target_ids: Ids of target tokens to compute log odds on\n",
    "        padding_mask: padding positions\n",
    "        \"\"\"\n",
    "        bs, seq = logits.size(0), logits.size(1)\n",
    "\n",
    "        # Gather the logits for at the masked positions\n",
    "        # TODO: More efficient implementation?\n",
    "        # Gather copies the data to create a new tensor which we would rather avoid\n",
    "        sel = (mask_positions.unsqueeze(1)\n",
    "                .unsqueeze(2).expand(bs, 1, logits.size(2))) # (batch, 1, V)\n",
    "        logits_at_masked_positions = logits.gather(1, sel).squeeze(1) # (batch, V)\n",
    "        \n",
    "        # Gather the logits for the target ids\n",
    "        sel = target_ids\n",
    "        target_logits_at_masked_positions = logits_at_masked_positions.gather(1, sel).squeeze(1) # (batch, 2)\n",
    "        \n",
    "        bias_loss = self.loss_func(\n",
    "            target_logits_at_masked_positions[:, 0], # male logits\n",
    "            target_logits_at_masked_positions[:, 1], # female logits\n",
    "            desired=desired_bias if desired_bias is not None else 0.,\n",
    "         )\n",
    "        \n",
    "        # compute log likelihood of either of the target ids being observed\n",
    "        ll = self._log_likelihood(logits_at_masked_positions,\n",
    "                                  target_logits_at_masked_positions)\n",
    "        \n",
    "        # enforce consistency between prior probabilities and current probabilities\n",
    "        consistency_loss = self._consistency_loss(\n",
    "            ll, initial_prob_sum,\n",
    "         )\n",
    "        out_dict = {}\n",
    "        out_dict[\"bias_loss\"] = bias_loss * self.bias_weight\n",
    "        out_dict[\"consistency_loss\"] = consistency_loss * self.consistency_weight\n",
    "        out_dict[\"loss\"] = out_dict[\"bias_loss\"] + out_dict[\"consistency_loss\"]\n",
    "        out_dict[\"total_prob_diff\"] = self._total_prob_diff(ll, initial_prob_sum)\n",
    "        return out_dict\n",
    "\n",
    "    def get_metrics(self, reset: bool = False) -> Dict[str, float]:\n",
    "        return {\"total_prob_diff\": self._total_prob_diff.get_metric(reset)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "to_words(batch[\"input\"][\"tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_loss = BiasLoss()\n",
    "logits = masked_lm(batch[\"input\"][\"tokens\"])\n",
    "bias_loss(logits, batch[\"mask_positions\"], batch[\"target_ids\"],\n",
    "          batch[\"initial_prob_sum\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = torch.softmax(logits[:, 1, :], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence, w1, w2 = \"[MASK] is a nurse\", \"he\", \"she\"\n",
    "\n",
    "tokens = tokenizer(sentence)\n",
    "mask_position = tokens.index(\"[MASK]\") + 1\n",
    "input_toks = [Token(w) for w in tokens]\n",
    "bert_input = (token_indexer.tokens_to_indices(input_toks, global_vocab, \"tokens\"))\n",
    "token_ids = torch.LongTensor(bert_input[\"tokens\"]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs[:, token_indexer.vocab[w1]] + probs[:, token_indexer.vocab[w2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"initial_prob_sum\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The allennlp model (for training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.models import Model\n",
    "\n",
    "class BERT(Model):\n",
    "    def __init__(self, vocab, bert_for_masked_lm, \n",
    "                 loss: nn.Module=BiasLoss()):\n",
    "        super().__init__(vocab)\n",
    "        self.bert_for_masked_lm = bert_for_masked_lm\n",
    "        self.loss = loss\n",
    "    \n",
    "    def forward(self, \n",
    "                input: TensorDict,\n",
    "                mask_positions: torch.LongTensor,\n",
    "                target_ids: torch.LongTensor,\n",
    "                initial_prob_sum: torch.FloatTensor,\n",
    "                desired_bias: torch.FloatTensor=None,\n",
    "            ) -> TensorDict:\n",
    "        logits = self.bert_for_masked_lm(input[\"tokens\"])\n",
    "        # most of processing takes place in loss func\n",
    "        out_dict = self.loss(logits, mask_positions, \n",
    "                             target_ids, initial_prob_sum,\n",
    "                             desired_bias=desired_bias,\n",
    "                            )\n",
    "        out_dict[\"logits\"] = logits\n",
    "        return out_dict\n",
    "    \n",
    "    def get_metrics(self, reset: bool=False):\n",
    "        return self.loss.get_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_distance = mae_loss\n",
    "\n",
    "loss = BiasLoss(\n",
    "    loss_func=logit_distance,\n",
    "    consistency_loss_func=LogitConsistency(logit_distance),\n",
    "    bias_weight=config.bias_weight,\n",
    "    consistency_weight=config.consistency_weight,\n",
    ")\n",
    "model = BERT(global_vocab, masked_lm, loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_dict = dict(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(init_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_weights = {k: deepcopy(v) for k, v in model.named_parameters()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias scores before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_lm.eval()\n",
    "logits = masked_lm(processor.to_bert_model_input(\"[MASK] is a housemaid\"))[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits[ttoi(\"he\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits[ttoi(\"she\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = torch.softmax(logits.unsqueeze(0), 1).squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs[ttoi(\"he\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs[ttoi(\"she\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For word not in vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = masked_lm(processor.to_bert_model_input(\"[MASK] is a slut\"))[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits[ttoi(\"he\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits[ttoi(\"she\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = torch.softmax(logits.unsqueeze(0), 1).squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs[ttoi(\"he\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs[ttoi(\"she\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability distribution for unrelated sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_topk_preds(masked_sentence, k=5, strlen=30):\n",
    "    mask_idx = [x.text for x in processor.tokenize(masked_sentence)].index(\"[MASK]\") + 1\n",
    "    logits = masked_lm(processor.to_bert_model_input(masked_sentence))\n",
    "    probs = torch.softmax(logits.squeeze(0), 1)\n",
    "    topk = []\n",
    "    for p, id_ in zip(*probs[mask_idx, :].topk(k)):\n",
    "        topk.append((\"%.4f\" % p.item(), itot(id_.item())))\n",
    "    print(\"\\n\".join([f\"{masked_sentence.replace('[MASK]', w)}:{' ' * (strlen - len(w) - len(p))}{p}\" for p, w in topk]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_topk_preds(\"i ride my [MASK] to work\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_topk_preds(\"the [MASK] wagged its tail\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_topk_preds(\"the fish [MASK] through the water\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confirming Bias Scores Before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bias_score(row):\n",
    "    sentence, fword, mword, prior_bias = [row[k] for k in [\"sentence\", \"fword\", \"mword\", \"prior_bias\"]]\n",
    "    mask_pos = tokenizer(sentence).index(\"[MASK]\") + 1\n",
    "    logits = masked_lm(processor.to_bert_model_input(sentence)).squeeze(0)\n",
    "    i1,i2 = ttoi(fword),ttoi(mword)\n",
    "    log_odds = logits[mask_pos, i1] - logits[mask_pos, i2]\n",
    "    bias_correction = prior_bias\n",
    "    return (log_odds - bias_correction).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(DATA_ROOT / config.train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_train[\"original_bias_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = pd.read_csv(DATA_ROOT / config.val_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_val[\"original_bias_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.training import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "class StatisticRecorder(Callback):\n",
    "    def __init__(self, orig_weights, rec_periods=1):\n",
    "        self.rec_periods = rec_periods\n",
    "        self.norms = {k: [] for k, v in model.named_parameters() if v.requires_grad}\n",
    "        self.grad_magnitudes = {k: [] for k, v in model.named_parameters() if v.requires_grad}\n",
    "        self._orig_weights = orig_weights\n",
    "        self.change_magnitudes = {k: [] for k, v in model.named_parameters() if v.requires_grad}\n",
    "        \n",
    "    def on_batch_end(self, data):\n",
    "        if (data['batches_this_epoch'] + 1) % self.rec_periods == 0:\n",
    "            with torch.no_grad():\n",
    "                for k, p in self.trainer.model.named_parameters():\n",
    "                    if p.requires_grad and p.grad is not None:\n",
    "                        Z = torch.norm(p).item()\n",
    "                        self.norms[k].append(Z)\n",
    "                        self.grad_magnitudes[k].append((torch.norm(p.grad) / Z).item())\n",
    "                        self.change_magnitudes[k].append((torch.norm(p - self._orig_weights[k]) / Z).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightDeviationRegularizor(Callback):\n",
    "    def __init__(self, orig_weights, weight=1e-4, l1=True):\n",
    "        self.orig_weights = orig_weights\n",
    "        self.weight = weight\n",
    "        self.l1 = l1\n",
    "        \n",
    "    def get_reg_term(self, now, orig):\n",
    "        if self.l1:\n",
    "            return torch.where(now < orig, torch.ones_like(now), -torch.ones_like(now))\n",
    "        else:\n",
    "            return (orig - now)\n",
    "        \n",
    "    def on_backward_end(self, data):\n",
    "        lr = config.lr\n",
    "        with torch.no_grad():\n",
    "            for name, param in self.trainer.model.named_parameters():\n",
    "                if param.requires_grad and param.grad is not None:\n",
    "                    reg_term = self.weight * lr * self.get_reg_term(param.data, orig_weights[name])\n",
    "                    param.data.add_(reg_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "class LossMonitor(Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.logs = defaultdict(list)\n",
    "    def on_forward_end(self, payload):\n",
    "        for k, v in payload.items():\n",
    "            if \"loss\" in k: self.logs[k].append(v.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_rec = StatisticRecorder(orig_weights, rec_periods=1)\n",
    "wdd = WeightDeviationRegularizor(orig_weights, weight=config.weight_reg)\n",
    "monitor = LossMonitor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use(name: str):\n",
    "    if \"LayerNorm\" in name: return False\n",
    "    if \"position_embeddings\" in name: return False\n",
    "    if \"token_type\" in name: return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_params = [p for name, p in model.named_parameters() if use(name)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(filtered_params, lr=config.lr, weight_decay=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.training.learning_rate_schedulers import SlantedTriangular, CosineWithRestarts\n",
    "# use slanted triangular lr scheduler to prevent initial spike in consistency loss\n",
    "lr_sched = SlantedTriangular(optimizer, \n",
    "                             num_epochs=config.epochs, \n",
    "                             num_steps_per_epoch=iterator.get_num_batches(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.training import TrainerWithCallbacks\n",
    "\n",
    "trainer = TrainerWithCallbacks(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    iterator=iterator,\n",
    "    train_dataset=train_ds,\n",
    "    validation_dataset=val_ds,\n",
    "    callbacks=[stat_rec, wdd, monitor],\n",
    "    learning_rate_scheduler=lr_sched,\n",
    "    #     serialization_dir=DATA_ROOT / \"debias_ckpts\",\n",
    "    cuda_device=0 if torch.cuda.is_available() else -1,\n",
    "    num_epochs=config.epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_sorted_weights = sorted([(-v[-1], k) for k, v in stat_rec.change_magnitudes.items() if len(v) > 0])\n",
    "{k.replace(\"bert_for_masked_lm.bert.encoder.\", \"\"): -x for x, k in change_sorted_weights}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "fig = plt.figure(figsize=(10, n * 4))\n",
    "for i, (_, k) in enumerate(change_sorted_weights[:n]):\n",
    "    ax = fig.add_subplot(n, 1, i+1)\n",
    "    ax.plot(stat_rec.grad_magnitudes[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change in loss breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 30))\n",
    "ax = fig.add_subplot(n, 1, 1)\n",
    "ax.plot(monitor.logs[\"bias_loss\"], label=\"bias loss\")\n",
    "ax.plot(monitor.logs[\"consistency_loss\"], label=\"consistency loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds(model, batch: TensorDict):\n",
    "    return model(**batch)[\"logits\"].argmax(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_words(batch[\"input\"][\"tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_words(get_preds(model, batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logits and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_lm.eval()\n",
    "logits = masked_lm(processor.to_bert_model_input(\"[MASK] is a housemaid\"))[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits[ttoi(\"he\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits[ttoi(\"she\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = torch.softmax(logits.unsqueeze(0), 1).squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs[ttoi(\"he\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs[ttoi(\"she\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For an example not in the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = masked_lm(processor.to_bert_model_input(\"[MASK] is a slut\"))[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits[ttoi(\"he\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits[ttoi(\"she\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = torch.softmax(logits.unsqueeze(0), 1).squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs[ttoi(\"he\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs[ttoi(\"she\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changes to output distribution of unrelated sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_topk_preds(\"i ride my [MASK] to work\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_topk_preds(\"the [MASK] wagged its tail\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_topk_preds(\"the fish [MASK] through the water\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation on bias score across the train and val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"bias_score_after\"] = df_train.progress_apply(compute_bias_score, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_train[\"bias_score_after\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decrease is smaller than expected: perhaps more training is necessary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"original_bias_score\"].abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"bias_score_after\"].abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val[\"bias_score_after\"] = df_val.progress_apply(compute_bias_score, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val[\"original_bias_score\"].abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val[\"bias_score_after\"].abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As PyTorch state dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(masked_lm.state_dict(), MODEL_SAVE_DIR / \"state_dict.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Export as tensorflow checkpoint?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
