{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.tokenization:loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\\Users\\pedro\\.pytorch_pretrained_bert\\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenized input\n",
    "text = \"[CLS] Who was Jim Henson ? [SEP] Jim Henson was a puppeteer [SEP]\"\n",
    "tokenized_text = tokenizer.tokenize(text)\n",
    "\n",
    "# Mask a token that we will try to predict back with `BertForMaskedLM`\n",
    "masked_index = 8\n",
    "tokenized_text[masked_index] = '[MASK]'\n",
    "assert tokenized_text == ['[CLS]', 'who', 'was', 'jim', 'henson', '?', '[SEP]', 'jim', '[MASK]', 'was', 'a', 'puppet', '##eer', '[SEP]']\n",
    "\n",
    "# Convert token to vocabulary indices\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "# Define sentence A and B indices associated to 1st and 2nd sentences (see paper)\n",
    "segments_ids = [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n",
    "\n",
    "# Convert inputs to PyTorch tensors\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.modeling:loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\\Users\\pedro\\.pytorch_pretrained_bert\\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "INFO:pytorch_pretrained_bert.modeling:extracting archive file C:\\Users\\pedro\\.pytorch_pretrained_bert\\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\\Users\\pedro\\AppData\\Local\\Temp\\tmpebij7_e3\n",
      "INFO:pytorch_pretrained_bert.modeling:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "model.eval()\n",
    "\n",
    "# If you have a GPU, put everything on cuda\n",
    "tokens_tensor = tokens_tensor.to('cuda')\n",
    "segments_tensors = segments_tensors.to('cuda')\n",
    "model.to('cuda')\n",
    "\n",
    "# Predict hidden states features for each layer\n",
    "with torch.no_grad():\n",
    "    encoded_layers, _ = model(tokens_tensor, segments_tensors)\n",
    "# We have a hidden states for each of the 12 layers in model bert-base-uncased\n",
    "assert len(encoded_layers) == 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[ 0.1779, -0.1300, -0.1322,  ..., -0.0523,  0.0398,  0.1696],\n",
       "          [ 0.0015,  0.6659, -0.2717,  ...,  0.0858,  0.0752, -0.7998],\n",
       "          [-0.3025, -0.7966,  0.2017,  ..., -0.2160,  0.1442,  0.1139],\n",
       "          ...,\n",
       "          [ 0.9641, -0.2486, -0.5867,  ..., -0.2504, -0.1085,  0.9230],\n",
       "          [ 1.0382,  0.2008, -0.5151,  ...,  0.2307, -0.2571,  0.0853],\n",
       "          [-0.1584,  0.2854,  0.1234,  ...,  0.0381,  0.6913,  0.1684]]],\n",
       "        device='cuda:0'),\n",
       " tensor([[[ 0.0990, -0.0730, -0.1330,  ..., -0.1048, -0.0753,  0.0759],\n",
       "          [-0.3714,  0.7424, -0.4032,  ...,  0.3164, -0.2033, -1.2496],\n",
       "          [-0.2573, -0.0635,  0.0321,  ..., -0.4019,  0.1892, -0.4282],\n",
       "          ...,\n",
       "          [ 0.9812,  0.2636, -0.0527,  ..., -0.1582,  0.2423,  0.7502],\n",
       "          [ 1.3446,  0.3007, -0.3358,  ...,  0.4241, -0.2855, -0.5207],\n",
       "          [-0.2775,  0.2715,  0.2500,  ...,  0.0594,  0.5329,  0.0695]]],\n",
       "        device='cuda:0'),\n",
       " tensor([[[-4.0789e-02,  4.4493e-02, -2.2129e-02,  ..., -1.8704e-02,\n",
       "           -4.3142e-02,  1.3688e-01],\n",
       "          [-7.2597e-01,  7.8354e-01,  2.7171e-01,  ...,  1.8130e-01,\n",
       "           -3.9206e-01, -9.0022e-01],\n",
       "          [-5.0371e-01,  7.3856e-02,  2.5070e-01,  ..., -4.2008e-01,\n",
       "            2.3007e-01, -4.5515e-01],\n",
       "          ...,\n",
       "          [ 1.1089e+00,  3.0150e-01,  4.4696e-01,  ..., -6.8307e-02,\n",
       "            5.7064e-01,  4.9117e-01],\n",
       "          [ 1.0356e+00,  6.3827e-01, -2.7184e-01,  ...,  1.4740e-01,\n",
       "           -6.3119e-01, -7.2353e-01],\n",
       "          [-8.3044e-02, -1.2659e-02,  1.3316e-01,  ...,  9.7616e-02,\n",
       "            7.9972e-02,  1.0272e-03]]], device='cuda:0'),\n",
       " tensor([[[-3.9109e-01,  1.7313e-01, -2.0164e-01,  ..., -2.1900e-01,\n",
       "           -3.7430e-02,  5.9758e-01],\n",
       "          [-7.2134e-01,  2.0570e-01,  5.4327e-01,  ...,  2.4376e-01,\n",
       "           -6.5600e-01, -1.2623e+00],\n",
       "          [-4.2893e-01,  1.9687e-01,  3.0457e-01,  ..., -5.1878e-01,\n",
       "            2.1816e-01, -6.9328e-02],\n",
       "          ...,\n",
       "          [ 1.0461e+00,  1.4166e-01,  3.7233e-01,  ..., -8.2297e-02,\n",
       "            6.0216e-01,  3.7988e-01],\n",
       "          [ 5.2007e-01,  8.3337e-01, -5.0424e-01,  ..., -1.7417e-01,\n",
       "           -5.9790e-01, -6.9891e-01],\n",
       "          [-4.6407e-02, -1.1241e-02,  1.4170e-02,  ...,  2.5845e-02,\n",
       "            2.8524e-02,  8.1989e-04]]], device='cuda:0'),\n",
       " tensor([[[-0.7761,  0.6735, -0.6933,  ...,  0.0564,  0.1930,  0.7531],\n",
       "          [-0.4646, -0.2884,  0.0519,  ...,  0.5180, -0.3244, -1.5044],\n",
       "          [-0.6151, -0.3375,  0.1852,  ..., -0.6456,  0.8882,  0.0056],\n",
       "          ...,\n",
       "          [ 1.0842,  0.1205,  0.0039,  ...,  0.3088,  0.7306,  0.1681],\n",
       "          [ 0.2433,  0.8395,  0.2326,  ..., -0.4409, -0.4829, -0.9962],\n",
       "          [-0.0206, -0.0180, -0.0054,  ...,  0.0268, -0.0126, -0.0147]]],\n",
       "        device='cuda:0'),\n",
       " tensor([[[-0.8627,  1.0387, -1.3689,  ..., -0.1120, -0.3449,  0.7689],\n",
       "          [-0.5745, -0.3801,  0.3313,  ...,  0.5633, -0.2727, -1.5486],\n",
       "          [-0.4938, -0.2021, -0.2411,  ..., -0.5992,  0.9025, -0.0218],\n",
       "          ...,\n",
       "          [ 0.9449,  0.1948,  0.1223,  ...,  0.0534,  0.4925,  0.2550],\n",
       "          [ 0.0667,  1.2551,  0.1510,  ..., -0.8011, -0.5844, -0.8700],\n",
       "          [ 0.0082,  0.0133, -0.0207,  ...,  0.0203, -0.0227, -0.0327]]],\n",
       "        device='cuda:0'),\n",
       " tensor([[[-2.6838e-01,  1.2196e+00, -1.4711e+00,  ..., -1.7785e-01,\n",
       "           -1.7673e-01,  1.3198e+00],\n",
       "          [-1.0829e+00, -1.8917e-01, -1.3025e-01,  ...,  3.6318e-01,\n",
       "            9.7160e-02, -1.4456e+00],\n",
       "          [-1.8401e-01, -4.2951e-01, -1.5649e-01,  ..., -4.4925e-01,\n",
       "            6.3047e-01, -3.3546e-01],\n",
       "          ...,\n",
       "          [ 6.0729e-01,  1.0230e-01,  4.0650e-01,  ...,  3.5214e-01,\n",
       "            9.1784e-01,  6.5051e-02],\n",
       "          [-4.0925e-02,  1.1832e+00,  2.4925e-01,  ..., -4.1765e-01,\n",
       "           -3.6966e-01, -8.9656e-01],\n",
       "          [ 2.9085e-02,  1.6743e-02, -2.6046e-02,  ..., -3.5536e-05,\n",
       "           -6.7228e-03, -5.8149e-02]]], device='cuda:0'),\n",
       " tensor([[[-0.4923,  0.9383, -1.3125,  ..., -0.5090,  0.0756,  1.0566],\n",
       "          [-0.8576, -0.5833, -0.1757,  ...,  0.3493, -0.1316, -0.9785],\n",
       "          [-0.0537, -0.8009, -0.0827,  ..., -0.0833,  0.8288, -0.0140],\n",
       "          ...,\n",
       "          [ 0.3333, -0.0029,  0.4160,  ...,  0.4595,  1.0069,  0.0142],\n",
       "          [-0.3981,  1.0850,  0.4030,  ..., -0.0605,  0.0286, -0.8406],\n",
       "          [ 0.0501,  0.0505,  0.0220,  ..., -0.0216, -0.0507, -0.0409]]],\n",
       "        device='cuda:0'),\n",
       " tensor([[[-0.7925,  0.9943, -1.2889,  ..., -0.3039,  0.3672,  0.8740],\n",
       "          [-1.0071, -0.6564, -0.1729,  ..., -0.0266, -0.1763, -0.7959],\n",
       "          [ 0.1068, -0.8260, -0.0257,  ...,  0.2849,  0.4516, -0.0519],\n",
       "          ...,\n",
       "          [ 0.1786,  0.1168,  0.0944,  ...,  0.1606,  0.9940, -0.0134],\n",
       "          [-0.3210,  0.8753,  0.0322,  ..., -0.0870,  0.4237, -0.7533],\n",
       "          [ 0.0542,  0.1283, -0.0363,  ..., -0.0399, -0.0667,  0.0462]]],\n",
       "        device='cuda:0'),\n",
       " tensor([[[-0.9753,  0.7123, -1.1111,  ..., -0.3962,  0.6702,  0.6424],\n",
       "          [-1.1344, -0.5079, -0.2038,  ..., -0.0971,  0.2238, -0.7655],\n",
       "          [ 0.1231, -0.8080, -0.6852,  ...,  0.2233,  0.7257,  0.4268],\n",
       "          ...,\n",
       "          [ 0.1566,  0.0505,  0.1393,  ...,  0.0744,  1.0839, -0.1500],\n",
       "          [-0.3584,  0.4886,  0.3353,  ...,  0.1377,  0.3363, -0.7418],\n",
       "          [ 0.0212,  0.0102, -0.0637,  ...,  0.0488, -0.0185,  0.0048]]],\n",
       "        device='cuda:0'),\n",
       " tensor([[[-0.7692,  0.4471, -0.8988,  ..., -0.6973,  0.4634,  0.6683],\n",
       "          [-1.6097, -0.2628, -0.1208,  ...,  0.0024,  0.1172, -0.6110],\n",
       "          [-0.0723, -0.7547, -0.2052,  ..., -0.1477,  0.6579,  0.5760],\n",
       "          ...,\n",
       "          [ 0.2651,  0.0262,  0.2382,  ..., -0.2149,  1.0711, -0.1187],\n",
       "          [-0.4854,  0.4848,  0.6682,  ...,  0.2559,  0.2955, -0.5611],\n",
       "          [ 0.0455,  0.0267, -0.0420,  ...,  0.0073, -0.0151,  0.0157]]],\n",
       "        device='cuda:0'),\n",
       " tensor([[[-0.5570,  0.2839, -0.6436,  ..., -0.7274,  0.4557,  0.6204],\n",
       "          [-1.1572,  0.0354,  0.0355,  ...,  0.0591,  0.1097, -0.3150],\n",
       "          [ 0.1008, -0.5286, -0.4688,  ..., -0.0431,  0.4889,  0.4134],\n",
       "          ...,\n",
       "          [ 0.1948,  0.0761,  0.2893,  ..., -0.0807,  0.7071,  0.0502],\n",
       "          [-0.1119,  0.0714,  0.6101,  ...,  0.4044,  0.1614, -0.3569],\n",
       "          [ 0.8296,  0.2729, -0.3090,  ...,  0.2452, -0.3581, -0.1970]]],\n",
       "        device='cuda:0')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.modeling:loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\\Users\\pedro\\.pytorch_pretrained_bert\\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "INFO:pytorch_pretrained_bert.modeling:extracting archive file C:\\Users\\pedro\\.pytorch_pretrained_bert\\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\\Users\\pedro\\AppData\\Local\\Temp\\tmpqrp8vwv6\n",
      "INFO:pytorch_pretrained_bert.modeling:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "INFO:pytorch_pretrained_bert.modeling:Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model (weights)\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "model.eval()\n",
    "\n",
    "# If you have a GPU, put everything on cuda\n",
    "tokens_tensor = tokens_tensor.to('cuda')\n",
    "segments_tensors = segments_tensors.to('cuda')\n",
    "model.to('cuda')\n",
    "\n",
    "# Predict all tokens\n",
    "with torch.no_grad():\n",
    "    predictions = model(tokens_tensor, segments_tensors)\n",
    "\n",
    "# confirm we were able to predict 'henson'\n",
    "predicted_index = torch.argmax(predictions[0, masked_index]).item()\n",
    "predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n",
    "assert predicted_token == 'henson'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'henson'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded_layers[11][0][8])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.3325e-01,  1.6397e-01,  2.1220e-01,  2.4581e-01,  3.5942e-01,\n",
       "        -1.8511e-01, -8.9237e-02,  5.9655e-01, -2.3936e-02,  4.3561e-01,\n",
       "        -6.5029e-02, -2.2378e-02, -7.8029e-02,  8.6534e-02, -3.9485e-01,\n",
       "         2.8866e-01,  4.2361e-01,  2.6790e-02, -2.1295e-01, -5.3584e-01,\n",
       "         2.5959e-01, -2.5565e-01,  2.1842e-01, -1.5863e-01,  5.7914e-01,\n",
       "         6.2407e-01, -1.3453e-01,  2.0321e-01, -1.3450e-01,  1.3699e-01,\n",
       "         2.9377e-01, -6.2752e-01,  2.2628e-01, -5.2016e-01, -1.1211e-01,\n",
       "         3.5283e-01, -1.1038e-02, -2.6902e-01, -3.1812e-01,  8.3966e-02,\n",
       "        -6.7615e-01,  1.4772e-02,  4.8851e-02,  5.5387e-01,  1.0909e-01,\n",
       "        -8.9501e-02, -1.3482e-01, -2.9250e-01, -1.5335e-01, -2.5051e-01,\n",
       "        -6.2847e-01, -2.7293e-01, -2.7769e-01, -2.2177e-02,  8.9669e-02,\n",
       "        -2.0880e-01,  1.2952e-01,  4.5479e-03,  5.3365e-01, -2.0591e-01,\n",
       "         1.1390e-01, -1.4905e-01, -2.7777e-02, -4.7949e-01, -3.4620e-01,\n",
       "        -1.0370e-01,  4.0764e-01,  2.3562e-01,  1.6936e-01,  1.2066e-01,\n",
       "        -3.0635e-01, -2.0677e-01, -9.0776e-02,  2.8242e-01,  1.1846e-01,\n",
       "        -2.0160e-01,  4.5170e-01, -6.1032e-02,  7.3292e-02,  9.8362e-02,\n",
       "         2.6008e-01,  2.7672e-01,  2.2325e-01,  2.1885e-01,  2.0634e-01,\n",
       "        -1.2709e-01,  7.6079e-02, -2.2261e-01, -2.9770e-01,  2.6001e-01,\n",
       "        -4.8116e-01,  1.9743e-01,  1.4412e-01,  3.2134e-01,  1.0498e-01,\n",
       "        -5.4587e-01,  1.0334e-01, -4.5297e-01,  1.1439e-01,  1.9224e-01,\n",
       "        -2.1971e-01,  2.1173e-01,  2.7172e-01, -2.1112e-02, -1.2198e-01,\n",
       "        -7.8508e-02,  6.8018e-02, -1.2654e-01, -3.1125e-01,  6.9451e-01,\n",
       "        -3.6461e-01,  3.7582e-01,  3.9246e-01, -3.2342e-01,  7.1845e-02,\n",
       "         2.0578e-01,  2.6010e-01,  1.6918e-01, -1.6799e-01,  5.3382e-01,\n",
       "         4.7612e-01,  2.9579e-01,  1.9836e-01, -1.9155e-01,  9.6364e-02,\n",
       "        -3.6857e-01, -9.5902e-02, -4.2180e-02, -2.2746e-01, -3.6482e-01,\n",
       "         4.9266e-01,  3.6676e-02,  1.6923e-01, -3.9071e-01, -1.3315e-01,\n",
       "         1.0750e-01, -3.1076e-01,  1.2808e-01,  3.0950e-03, -4.9617e-01,\n",
       "         3.8857e-01, -1.7322e-01, -9.1249e-02, -2.5447e-01,  4.8266e-01,\n",
       "        -1.8139e-01, -4.2334e-01,  3.3665e-01,  2.1318e-01, -2.3154e-01,\n",
       "         5.4413e-01,  1.3551e-01,  8.4410e-02, -6.4033e-01, -7.8900e-02,\n",
       "        -3.0652e-02,  7.8603e-02, -7.8128e-02,  3.4286e-01,  2.0046e-03,\n",
       "        -1.7290e-01,  5.2425e-02,  2.2697e-01,  2.4885e-01, -1.9873e-01,\n",
       "        -5.1581e-01, -1.9777e-01, -2.8061e-01, -2.8155e-01, -1.8621e-01,\n",
       "        -2.6378e-02,  1.8163e-01,  6.0740e-02,  1.7627e-01,  3.2966e-01,\n",
       "         2.4926e-01,  9.7055e-01,  6.6236e-02,  2.5670e-01,  3.3894e-01,\n",
       "        -4.4449e-02, -1.4807e-01,  1.8044e-01,  5.3375e-01, -3.0511e-01,\n",
       "        -1.4849e-01,  1.2794e-01, -5.4645e-01,  2.8788e-01,  1.4599e-01,\n",
       "        -5.4501e-01, -5.5917e-01,  3.0625e-01, -3.9314e-01,  5.3024e-02,\n",
       "        -1.9974e-01, -1.6685e-01, -6.8685e-02, -1.9576e-01,  1.3177e-01,\n",
       "         3.8505e-01,  4.2670e-01, -3.0016e-01,  2.0094e-01, -1.7502e-01,\n",
       "         1.0837e-01, -6.6007e-02,  2.7013e-01,  4.9627e-01,  3.2445e-01,\n",
       "         1.7427e-01,  3.9181e-01,  8.3456e-02,  9.1882e-02,  2.7054e-01,\n",
       "        -3.0867e-01,  1.6751e-01, -2.7281e-01,  1.3857e-01,  5.7402e-02,\n",
       "         2.9350e-01, -4.6757e-01,  1.1633e-01, -3.7258e-01,  1.5315e-01,\n",
       "         2.2652e-01,  3.2471e-01, -3.5764e-01,  4.9046e-01,  2.1689e-01,\n",
       "        -3.3077e-01,  2.5724e-01, -7.3036e-02,  2.5488e-01, -7.6197e-02,\n",
       "        -1.5526e-01,  2.2531e-01, -6.2242e-01,  4.8193e-02, -9.5261e-02,\n",
       "         3.2552e-02, -2.8174e-01,  3.5543e-01,  1.7514e-01,  2.6105e-01,\n",
       "        -3.3469e-01, -6.9335e-02,  2.3452e-01, -5.8648e-01,  1.2053e-01,\n",
       "         5.0128e-01, -1.9113e-02,  5.8286e-01,  2.9860e-01,  2.4557e-01,\n",
       "        -4.5804e-01,  1.2667e-01, -3.2015e-01,  2.3341e-01,  3.4751e-01,\n",
       "        -3.5469e-03,  1.1641e-01, -4.5189e-02,  1.3298e-01, -4.0281e-01,\n",
       "        -4.4852e-01, -1.3620e-01,  8.3751e-04, -4.9524e-01,  1.4473e-01,\n",
       "         3.6952e-01, -2.1396e-01, -2.1541e-01,  1.1147e-01,  4.0539e-01,\n",
       "        -1.8842e-01,  3.2193e-01, -2.3561e-01, -6.8929e-03, -2.7779e-01,\n",
       "        -2.1406e-01,  5.1748e-01, -6.9047e-01, -2.1807e-01, -2.7074e-01,\n",
       "        -3.1775e-01, -3.8999e-01,  1.0695e-02, -2.4725e-01, -2.0811e-01,\n",
       "         1.2245e-01,  3.2359e-01,  1.5241e-01,  2.6326e-01,  1.9703e-01,\n",
       "         2.6145e-01,  5.1186e-01,  2.8682e-01,  1.3098e-01, -3.9629e-01,\n",
       "        -1.4174e-01,  2.6435e-01,  3.2570e-01,  1.9673e-01,  1.5021e-01,\n",
       "         2.4439e-01,  1.8205e-01, -1.9409e-01, -6.4628e+00,  3.6696e-01,\n",
       "        -1.0665e-01,  1.3788e-01,  1.3651e-01, -9.9371e-02,  1.9592e-01,\n",
       "        -1.4627e-01,  1.6542e-01,  2.4797e-01, -4.9935e-01,  1.8486e-01,\n",
       "         3.7288e-02,  3.4070e-01,  1.7826e-01, -1.9596e-01, -1.2218e-02,\n",
       "        -4.3346e-01,  1.5277e-01,  2.0773e-01, -2.3132e-01, -5.6752e-01,\n",
       "         1.1387e-01, -5.2132e-01,  1.2839e-01, -2.1834e-02, -3.3415e-01,\n",
       "        -7.6108e-02,  2.4545e-02, -3.3539e-03, -1.4868e-01, -5.3726e-01,\n",
       "         7.9609e-03, -5.0323e-01,  1.2297e-01,  2.0744e-01, -2.1770e-01,\n",
       "        -1.0386e-01,  9.3587e-03,  6.6875e-02,  4.2787e-01, -6.9750e-01,\n",
       "        -9.7925e-02, -1.1341e-01,  5.8470e-01,  1.1010e-02, -4.0237e-01,\n",
       "         2.5279e-01,  1.6114e-01,  2.2735e-01,  5.2073e-01,  3.1482e-01,\n",
       "        -1.2575e-01,  2.0528e-01,  3.8209e-01, -4.2386e-01, -4.4935e-02,\n",
       "        -6.9462e-02, -2.0719e-01, -4.4781e-01,  4.9972e-01, -1.5720e-01,\n",
       "        -8.5580e-01, -7.3965e-02, -1.1375e-01, -6.7161e-01,  9.3933e-02,\n",
       "        -8.9018e-02,  3.6364e-01,  3.2090e-02,  1.4259e-01, -1.7620e-01,\n",
       "        -1.6117e-01, -3.9657e-01,  4.8128e-02,  4.1500e-01, -2.1578e-01,\n",
       "         1.3421e-01, -3.4545e-01, -7.1608e-02, -2.3980e-01, -3.5233e-01,\n",
       "         2.7997e-01, -1.7706e-01,  1.9660e-02, -2.0466e-01,  1.8920e-01,\n",
       "        -2.4640e-02,  9.7648e-02,  8.4577e-02,  9.6423e-02,  9.5003e-03,\n",
       "        -4.9086e-01,  2.9321e-01,  1.9143e-01, -3.9728e-01,  4.4818e-01,\n",
       "         3.3247e-01,  4.5600e-01, -1.4816e-01, -9.4577e-02, -2.5740e-01,\n",
       "        -5.2777e-01, -2.4592e-01,  1.4718e-01,  7.1283e-02, -4.4059e-02,\n",
       "         1.3849e-01,  1.1728e-01, -5.2553e-02, -5.5056e-02, -4.9817e-02,\n",
       "        -6.5647e-01, -4.2505e-01, -2.0080e-01,  4.1041e-01,  1.8594e-01,\n",
       "         1.8288e-01, -3.8607e-01,  4.8246e-01, -1.6051e-01, -7.1884e-02,\n",
       "        -8.0488e-02,  1.2680e-01, -5.5498e-01, -1.7977e-01,  2.9308e-01,\n",
       "        -5.7300e-02,  2.1216e-01, -3.4991e-01, -1.7266e-02,  3.7033e-01,\n",
       "        -2.2443e-01,  9.6493e-03,  4.2222e-01, -1.7101e-01, -4.3423e-01,\n",
       "        -3.6649e-01,  1.6886e-01, -3.2642e-01,  2.0619e-01, -1.1100e-01,\n",
       "         3.8065e-01,  1.1289e-01, -4.2594e-01,  6.5538e-02, -9.6314e-02,\n",
       "        -2.8738e-01, -5.1121e-02,  1.8557e-01,  3.7921e-01,  1.6200e-01,\n",
       "        -7.1666e-03,  1.4803e-01, -4.3447e-01,  5.0292e-02,  1.5319e-01,\n",
       "        -2.0504e-01, -3.0948e-02, -4.5300e-02,  1.0472e-01, -5.7544e-01,\n",
       "        -8.1940e-02, -2.0953e-01, -2.6705e-02,  1.3540e-02, -1.2371e-01,\n",
       "         7.3783e-01,  1.5863e-01,  6.3183e-02,  4.0968e-01,  5.3077e-01,\n",
       "        -7.0265e-01,  4.1638e-01,  3.3674e-02,  6.0344e-01, -1.1622e-01,\n",
       "         6.1747e-02, -4.3573e-01,  6.5040e-01,  7.2640e-02, -4.6163e-01,\n",
       "        -8.3040e-03, -2.0913e-01,  2.7331e-02, -7.7374e-02, -2.7595e-01,\n",
       "        -2.2155e-01, -1.5380e-01, -3.6081e-01,  5.2969e-01,  1.8495e-01,\n",
       "         2.1407e-01,  1.0890e-01,  2.5923e-01, -4.8005e-02,  8.3508e-03,\n",
       "        -6.8639e-01,  1.2140e-01, -1.3534e-01, -5.4672e-01, -4.8110e-01,\n",
       "        -1.2573e-01, -8.2545e-02,  8.5212e-01, -4.9643e-01, -4.7797e-01,\n",
       "        -2.8059e-01, -2.3273e-01,  2.6533e-01, -1.5450e-02, -3.1167e-01,\n",
       "        -6.4051e-01,  1.4477e-01, -3.8347e-02, -6.3420e-02, -5.2347e-01,\n",
       "         2.9960e-01, -2.5599e-02,  4.9442e-02,  1.8218e-02, -8.4970e-02,\n",
       "         3.0981e-01,  1.0884e-01, -3.7668e-01,  3.8359e-04, -2.2255e-01,\n",
       "         3.7122e-01, -4.0156e-01, -7.9488e-01, -2.5171e-01,  2.3398e-01,\n",
       "         2.6900e-01,  5.5431e-01, -3.7457e-01, -2.8362e-01,  3.0598e-01,\n",
       "         3.3666e-01, -4.6648e-02,  3.1435e-01,  3.1735e-01,  1.8670e-01,\n",
       "        -1.9730e-01, -9.4755e-02, -4.1014e-02,  2.5107e-01, -2.7036e-01,\n",
       "        -1.7385e-01, -8.7294e-02, -2.4140e-01, -1.3937e-01,  7.2248e-02,\n",
       "        -2.6290e-01,  6.5282e-02,  3.3086e-01,  2.4309e-01,  1.9701e-01,\n",
       "        -6.1199e-01,  1.6764e-01, -6.4416e-01, -1.3963e-01,  7.5842e-01,\n",
       "         2.1258e-02,  7.8037e-01, -8.6193e-02, -3.4767e-02,  5.1410e-02,\n",
       "        -3.5771e-01,  2.0273e-01, -4.1131e-01, -1.7001e-02,  2.8150e-01,\n",
       "         7.7288e-02,  8.2466e-01,  2.0474e-01,  1.3297e-01,  7.3143e-02,\n",
       "        -2.9569e-01, -1.1393e-02,  1.0752e-01, -1.0729e-01,  6.6493e-01,\n",
       "        -3.0204e-01, -3.7536e-01, -4.6909e-02, -2.9296e-01,  1.3157e-01,\n",
       "        -1.9121e-01,  1.0506e-01, -2.9389e-01,  1.4842e-01,  3.6795e-02,\n",
       "         1.4680e-01,  8.3698e-02, -5.5449e-01, -1.9757e-01,  1.1965e-01,\n",
       "        -1.1527e-01, -1.2688e-01, -1.0906e-01, -3.5925e-01,  1.1843e-02,\n",
       "        -3.4907e-01, -2.8826e-01, -1.2267e-01, -2.2144e-01, -2.1642e-02,\n",
       "        -1.7401e-01, -7.4728e-02, -2.2430e-01, -3.8433e-01, -4.6754e-01,\n",
       "         3.9084e-01, -1.3374e-02, -1.9064e-01, -6.5138e-01,  4.8849e-01,\n",
       "         3.2069e-02,  1.7518e-01,  3.4744e-01,  1.9117e-01,  4.1312e-02,\n",
       "         3.0195e-01,  5.8352e-01, -2.9723e-01, -5.4807e-02, -4.7599e-02,\n",
       "        -2.4515e-01, -1.6299e-01,  3.9460e-01,  2.5174e-01,  4.4110e-02,\n",
       "         2.4743e-01,  1.3693e-01, -2.4628e-02, -7.0147e-01,  2.0176e-01,\n",
       "        -3.0496e-02, -4.4664e-02,  4.2283e-01, -3.6358e-01,  5.0332e-01,\n",
       "         3.8075e-01,  4.7214e-01,  1.5126e-01,  9.7129e-03,  1.4084e-01,\n",
       "         5.4311e-02, -5.5845e-01,  8.3673e-01, -2.9057e-01,  1.2520e-01,\n",
       "         2.4319e-01, -4.8539e-01,  2.1459e-01,  2.9496e-01, -2.5918e-01,\n",
       "        -3.3007e-01,  1.2744e-01, -2.2519e-02,  2.8005e-01, -3.5203e-01,\n",
       "         3.6504e-01,  2.3681e-01,  1.3107e-01,  2.0416e-01, -2.9236e-01,\n",
       "        -4.7244e-01,  1.6186e-01,  5.2887e-01,  8.8460e-02,  1.5775e-01,\n",
       "        -1.1006e-01, -1.7088e-02, -2.9750e-01,  1.4739e-01,  5.4261e-01,\n",
       "         2.3664e-01,  3.0616e-01, -5.4698e-02, -4.3277e-02,  4.0465e-02,\n",
       "         1.4870e-01,  1.9621e-02, -1.5604e-01,  1.0847e-01, -5.0768e-02,\n",
       "         4.0406e-01, -2.3290e-02, -4.0923e-01, -5.7621e-01, -2.6619e-01,\n",
       "         4.9059e-02,  4.2544e-02, -4.5712e-03, -3.4528e-01, -1.9553e-01,\n",
       "         2.5444e-02,  4.5200e-01,  2.3776e-02,  1.5777e-01,  5.5794e-01,\n",
       "        -6.6986e-02,  1.3734e-01,  1.3099e-01, -4.7073e-02,  1.9904e-01,\n",
       "        -3.5945e-01, -3.0836e-01,  5.0331e-02, -5.5808e-01,  5.3713e-01,\n",
       "        -3.1299e-01, -3.5455e-01,  1.8024e-01, -6.1181e-01, -1.1050e-01,\n",
       "        -2.0472e-01,  6.5629e-02, -3.5275e-01,  3.0522e-01,  2.7409e-01,\n",
       "        -4.3930e-01,  4.2414e-01, -3.4038e-01,  3.5510e-01,  2.1945e-01,\n",
       "        -4.2781e-01, -1.4178e-01, -2.2220e-01,  6.4719e-02,  1.4232e-01,\n",
       "        -3.8023e-01,  6.6485e-02,  7.6645e-02, -1.4580e-01, -6.7850e-02,\n",
       "         1.1315e-02, -1.9535e-01, -5.9271e-01, -6.6174e-02,  2.2931e-01,\n",
       "         1.3866e-01,  4.2080e-01, -3.8973e-02, -3.7859e-01,  3.1966e-01,\n",
       "         3.4094e-01,  2.4487e-02,  5.8183e-01, -2.4651e-02, -5.2376e-02,\n",
       "         4.9749e-01, -4.4107e-01,  2.1503e-01,  4.0224e-01,  2.4797e-01,\n",
       "        -1.6112e-01, -8.0615e-02,  4.8347e-01], device='cuda:0')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_layers[11][0][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
